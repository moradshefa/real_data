{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from data_loader import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "\n",
    "import keras\n",
    "from keras.layers import Input, Reshape, Conv2D, MaxPooling2D, ZeroPadding2D, Flatten, Dropout, Dense, LSTM,Activation\n",
    "from keras.models import Model, load_model\n",
    "from keras.utils import plot_model, multi_gpu_model\n",
    "\n",
    "from scipy import signal\n",
    "\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mod_group = 0 \n",
    "num_files = 2\n",
    "\n",
    "blc = 0\n",
    "\n",
    "CLASSES = ['16PSK', '2FSK_5KHz', '2FSK_75KHz', '8PSK', 'AM_DSB', 'AM_SSB', 'APSK16_c34',\n",
    " 'APSK32_c34', 'BPSK', 'CPFSK_5KHz', 'CPFSK_75KHz', 'FM_NB', 'FM_WB',\n",
    " 'GFSK_5KHz', 'GFSK_75KHz', 'GMSK', 'MSK', 'NOISE', 'OQPSK', 'PI4QPSK', 'QAM16',\n",
    " 'QAM32', 'QAM64', 'QPSK']\n",
    "\n",
    "all_mods = [np.arange(24), np.array([1,9,10,11,12,13]), np.array([4,5]), np.array([1,9]), np.array([6,7,20,21,22])]\n",
    "mods = all_mods[mod_group]\n",
    "modulations = [CLASSES[i] for i in mods]\n",
    "num_classes = mods.size\n",
    "\n",
    "path = \"/datax/yzhang/army_challenge/training_data/\"\n",
    "if blc == 0:\n",
    "    path = \"/datax/yzhang/training_data/\"\n",
    "\n",
    "data = []\n",
    "for i in range(num_files):\n",
    "    data_file = path + \"training_data_chunk_\" + str(i) + \".pkl\"\n",
    "    data.append(LoadModRecData(data_file, 1., 0., 0., load_mods=modulations))\n",
    "    \n",
    "data_file = path + \"training_data_chunk_14.pkl\"\n",
    "testdata = LoadModRecData(data_file, 1., 0., 0., load_mods=modulations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, title='Confusion matrix', cmap=plt.cm.Blues, labels=[]):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(labels))\n",
    "    plt.xticks(tick_marks, labels, rotation=45)\n",
    "    plt.yticks(tick_marks, labels)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_samples_in_instance = data[0].instance_shape[1]\n",
    "data[0].modTypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each modulation type, inspect some instances of data\n",
    "for modType in data[0].modTypes[:]:\n",
    "    min_SNR = -10\n",
    "    max_SNR = 10\n",
    "    snr_step = 4\n",
    "\n",
    "    # get random snr within valid range\n",
    "    snrValue = random.randrange(min_SNR, max_SNR, snr_step)\n",
    "\n",
    "    # get a collection of signals\n",
    "    collection_of_instances = data[0].dataCube[modType, snrValue]\n",
    "\n",
    "    # get the complex samples for a specific instance within the collection\n",
    "    cdata, index = get_complex_samples_for_instance(collection_of_instances)\n",
    "\n",
    "    # setup inspect\n",
    "    sample_rate = number_of_samples_in_instance\n",
    "    Ts = 1.0 / sample_rate\n",
    "    t = np.arange(0, len(cdata[0])) * Ts\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.title(modType)\n",
    "    plt.plot(cdata.squeeze().real)\n",
    "    plt.plot(cdata.squeeze().imag)\n",
    "    # inspect signal\n",
    "plt.show()    #data.inspect_signal(index, modType, snrValue, cdata[0], t.tolist(), number_of_samples_in_instance, sample_rate, 0, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def inception(input_img, fs=[64,64,64,64,64],height = 2, widths = [9,4],  with_residual=False):\n",
    "    tower_1 = Conv2D(filters=fs[0], kernel_size=[height, 1], padding='same',activation='relu')(input_img)\n",
    "    tower_2 = Conv2D(filters=fs[2], kernel_size=[height, 1], padding='same',activation='relu')(input_img)\n",
    "    tower_2 = Conv2D(filters=fs[3], kernel_size=[height, widths[0]], padding='same',activation='relu')(tower_2)\n",
    "    tower_3 = Conv2D(filters=fs[2], kernel_size=[height, 1], padding='same',activation='relu')(input_img)\n",
    "    tower_3 = Conv2D(filters=fs[3], kernel_size=[height, widths[1]], padding='same',activation='relu')(tower_3)\n",
    "    tower_4 = MaxPooling2D(3, strides=1, padding='same')(input_img)\n",
    "    tower_4 = Conv2D(filters=fs[4], kernel_size=1, padding='same',activation='relu')(tower_4)\n",
    "    \n",
    "    if len(widths) == 3:\n",
    "        tower_5 = Conv2D(filters=fs[2], kernel_size=[height, 1], padding='same',activation='relu')(input_img)\n",
    "        tower_5 = Conv2D(filters=fs[3], kernel_size=[height, widths[2]], padding='same',activation='relu')(tower_5)\n",
    "        output = keras.layers.concatenate([tower_1, tower_2, tower_3, tower_4, tower_5], axis = 3)\n",
    "    else:\n",
    "        output = keras.layers.concatenate([tower_1, tower_2, tower_3, tower_4], axis = 3)\n",
    "    if with_residual and output.shape==input_img.shape:\n",
    "        output = output+input_img\n",
    "    return output\n",
    "\n",
    "def out_tower(x, dr=0.5):\n",
    "    x = Dropout(dr)(x)\n",
    "    output = Flatten()(x)\n",
    "    logits = Dense(num_classes)(output)\n",
    "    out = Activation('softmax')(logits)\n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "def googleNet(x, data_format='channels_last', num_classes=24, num_layers = [1,1,1,1],features=[1,1,1,1,1]):\n",
    "    x = Reshape(in_shp + (1,), input_shape=in_shp)(x)\n",
    "    x = Conv2D(filters = 64*features[0], kernel_size=[2,7], strides=[1,2], data_format=data_format, padding='same', activation='relu')(x)\n",
    "    x = MaxPooling2D([1, 3], strides=[1,2], padding='same')(x)\n",
    "    for dep in range(num_layers[0]):\n",
    "        x = Conv2D(filters = 192*features[1], kernel_size=[1, 3], strides=[1,1], padding='same', activation='relu')(x)\n",
    "    x = MaxPooling2D([1,3], strides=[1,2], padding='same')(x)\n",
    "    for dep in range(num_layers[1]):\n",
    "        x = inception(x, widths=[9,4,12], fs=[128,32,32,32,32]*features[2])\n",
    "    x = MaxPooling2D(3, strides=2, padding='same')(x)\n",
    "    for dep in range(num_layers[2]):\n",
    "        x = inception(x, widths=[9,4], fs=[48,96,48,96,96]*features[3], with_residual=True)\n",
    "    x = MaxPooling2D(3, strides=2, padding='same')(x)\n",
    "    for dep in range(num_layers[3]):\n",
    "        x = inception(x,height = 1, fs=[64,32,32,32,32]*features[4])\n",
    "        \n",
    "    out = out_tower(x, dr=0.5)\n",
    "    return out\n",
    "\n",
    "in_shp = (2, 1024)\n",
    "input_img = Input(shape=in_shp)\n",
    "\n",
    "# for our final model we used num_layers = [1,2,6,2]\n",
    "out = googleNet(input_img,data_format='channels_last', num_classes=mods.size, num_layers = [1,1,1,1])\n",
    "model = Model(inputs=input_img, outputs=out)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# in_shp = (2, 1024)\n",
    "# input_img = Input(shape=in_shp)\n",
    "# x = Reshape(in_shp , input_shape=in_shp)(input_img)\n",
    "# # x = Conv2D(filters=32, kernel_size=(1,5), padding='same', activation='relu')(x)\n",
    "# # x = MaxPooling2D(pool_size=[2,2])(x)\n",
    "# x = LSTM(64, return_sequences=True, input_shape=(2,1024))(x)\n",
    "# # x = LSTM(64)(x)\n",
    "# x = Dense(5, activation='softmax')(x)\n",
    "# model = Model(inputs=input_img, outputs=x)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Uncomment to visualize architecture\n",
    "plot_model(model, to_file='model.png', show_shapes = True)\n",
    "\n",
    "figure(figsize = (15,20))\n",
    "img = mpimg.imread('model.png')\n",
    "plt.imshow(img, aspect='auto')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We trained till completion\n",
    "train_batch_size, number_of_epochs = 512, 1        \n",
    "\n",
    "val_batches = testdata.batch_iter(testdata.train_idx, train_batch_size, number_of_epochs, use_shuffle=False)\n",
    "vsteps = testdata.train_idx.size//train_batch_size\n",
    "\n",
    "\n",
    "generators = []\n",
    "tsteps = 0\n",
    "for d in data:\n",
    "    generators.append(d.batch_iter(d.train_idx, train_batch_size, number_of_epochs, use_shuffle=False))\n",
    "    tsteps += d.train_idx.size\n",
    "\n",
    "tsteps = tsteps//train_batch_size \n",
    "\n",
    "# from utils import perturb_batch\n",
    "\n",
    "def train_batches(noise=None):\n",
    "    while True:\n",
    "        batches_x, batches_y = [], []\n",
    "\n",
    "        for gen in generators:\n",
    "            batch_x, batch_y = next(gen)\n",
    "            batches_x.append(batch_x)\n",
    "            batches_y.append(batch_y)\n",
    "            \n",
    "        batches_x = np.concatenate(batches_x)\n",
    "        batches_y = np.concatenate(batches_y)\n",
    "        \n",
    "        ##### perturb\n",
    "#         batches_x = perturb_batch(batches_x, batches_y)    \n",
    "        #####\n",
    "        \n",
    "        \n",
    "        if noise:\n",
    "            x,y,z = batches_x.shape\n",
    "            batches_x += noise * np.random.randn(x, y, z)\n",
    "        idx = np.random.permutation(batches_x.shape[0])\n",
    "        \n",
    "        batches_x = batches_x[idx]\n",
    "        batches_y = batches_y[idx]\n",
    "        \n",
    "        for i in range(len(generators)):\n",
    "            beg = i * train_batch_size\n",
    "            end = beg + train_batch_size\n",
    "            yield batches_x[beg:end], batches_y[beg:end]\n",
    "        \n",
    "\n",
    "train_batches = train_batches(noise=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# model = multi_gpu_model(model, gpus=2)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "filepath = '/tmp/morads/convmodrecnets_CNN2_0.5.wts.h5'\n",
    "\n",
    "\n",
    "try:\n",
    "    history = model.fit_generator(train_batches,\n",
    "        nb_epoch=number_of_epochs,\n",
    "        steps_per_epoch=tsteps,\n",
    "        verbose=1,\n",
    "        validation_data=val_batches,\n",
    "        validation_steps=vsteps,\n",
    "         callbacks = [\n",
    "              keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss'    , verbose=0, save_best_only=True, mode='auto'),\n",
    "              keras.callbacks.EarlyStopping(monitor='val_loss', patience=5    , verbose=0, mode='auto')\n",
    "         ]) \n",
    "except(StopIteration):\n",
    "    pass\n",
    "    \n",
    "model.save('mod_classifier21.h5')  \n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "\n",
    "model = load_model('../../mod_group0_val_loss0546.h5')\n",
    "acc = {}\n",
    "snrs = np.arange(-15,15, 5)\n",
    "\n",
    "classes = testdata.modTypes\n",
    "\n",
    "print(\"classes \", classes)\n",
    "for snr in testdata.snrValues:\n",
    "\n",
    "    # extract classes @ SNR\n",
    "    snrThreshold_lower = snr\n",
    "    snrThreshold_upper = snr+5\n",
    "    snr_bounded_test_indicies = testdata.get_indicies_withSNRthrehsold(testdata.train_idx, snrThreshold_lower, snrThreshold_upper)\n",
    "    \n",
    "    test_X_i = testdata.signalData[snr_bounded_test_indicies]\n",
    "    test_Y_i = testdata.oneHotLabels[snr_bounded_test_indicies] \n",
    "\n",
    "    # estimate classes\n",
    "    test_Y_i_hat = model.predict(test_X_i)\n",
    "    conf = np.zeros([len(classes),len(classes)])\n",
    "    confnorm = np.zeros([len(classes),len(classes)])\n",
    "    for i in range(0,test_X_i.shape[0]):\n",
    "        j = list(test_Y_i[i,:]).index(1)\n",
    "        k = int(np.argmax(test_Y_i_hat[i,:]))\n",
    "        conf[j,k] = conf[j,k] + 1\n",
    "    for i in range(0,len(classes)):\n",
    "        confnorm[i,:] = conf[i,:] / np.sum(conf[i,:])\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plot_confusion_matrix(confnorm, labels=classes, title=\"ConvNet Confusion Matrix (SNR=%d)\"%(snr))\n",
    "    \n",
    "    cor = np.sum(np.diag(conf))\n",
    "    ncor = np.sum(conf) - cor\n",
    "    print(\"SNR\", snr, \"Overall Accuracy: \", cor / (cor+ncor), \"Out of\", len(snr_bounded_test_indicies))\n",
    "    acc[snr] = 1.0*cor/(cor+ncor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
