{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/morads/anaconda3/envs/py36/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from data_loader import *\n",
    "from numpy.fft import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "\n",
    "import keras\n",
    "from keras.models import Model, load_model\n",
    "from keras.utils import plot_model, multi_gpu_model\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "### Keras Conv2D\n",
    "from keras.layers import Input, Reshape, MaxPooling2D, ZeroPadding2D, Flatten, Dropout, Dense, LSTM,Activation,add\n",
    "# from keras.layers import Conv2D\n",
    "\n",
    "\n",
    "from convolutional import Complex_Conv1D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# path = \"/datax/yzhang/army_challenge/training_data/\"\n",
    "path = '/datax/yzhang/deepsig/2018.01/GOLD_XYZ_OSC.0001_1024.hdf5'\n",
    "f = h5py.File(path, 'r')\n",
    "\n",
    "classes = ['32PSK',                                                                     \n",
    " '16APSK',\n",
    " '32QAM',\n",
    " 'FM',\n",
    " 'GMSK',\n",
    " '32APSK',\n",
    " 'OQPSK',\n",
    " '8ASK',\n",
    " 'BPSK',\n",
    " '8PSK',\n",
    " 'AM-SSB-SC',\n",
    " '4ASK',\n",
    " '16PSK',\n",
    " '64APSK',\n",
    " '128QAM',\n",
    " '128APSK',\n",
    " 'AM-DSB-SC',\n",
    " 'AM-SSB-WC',\n",
    " '64QAM',\n",
    " 'QPSK',\n",
    " '256QAM',\n",
    " 'AM-DSB-WC',\n",
    " 'OOK',\n",
    " '16QAM']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2555904, 1024, 2)\n"
     ]
    }
   ],
   "source": [
    "data = np.asarray(f[\"X\"])\n",
    "labels = np.asarray(f[\"Y\"])\n",
    "snr = np.asarray(f[\"Z\"])\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2555904, 2, 1024)\n",
      "(2555904, 24)\n",
      "(2555904, 1)\n"
     ]
    }
   ],
   "source": [
    "# if set to true, we will add noise to the data\n",
    "# and train a model to classify snr 0: SNR<0; 1: SNR>=0; 2: NOISE\n",
    "train_snr = False\n",
    "\n",
    "new_labels = []\n",
    "\n",
    "def snr_to_one_hot(snr, labels):\n",
    "    num_unique_labels = 3\n",
    "    \n",
    "    new_labels = np.zeros((labels.shape[0], num_unique_labels))    \n",
    "    \n",
    "    new_labels[np.where(snr<0)[0],0] = 1\n",
    "    new_labels[np.where(snr>=0)[0],1] = 1\n",
    "    \n",
    "    return new_labels\n",
    "    \n",
    "    \n",
    "data = np.transpose(data, (0,2,1))\n",
    "    \n",
    "if train_snr:\n",
    "    labels = snr_to_one_hot(snr, labels)\n",
    "    \n",
    "print(data.shape)\n",
    "print(labels.shape)\n",
    "print(snr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load noise data from army\n",
    "if train_snr:\n",
    "    blc = 2\n",
    "    path = \"/datax/yzhang/army_challenge/training_data/\"\n",
    "    if blc == 0:\n",
    "        path = \"/datax/yzhang/training_data/\"\n",
    "\n",
    "    army_noise_data = []\n",
    "\n",
    "    num_noise_data = labels.shape[0] // 2\n",
    "    for i in range(15):\n",
    "        data_file = path + \"training_data_chunk_\" + str(i) + \".pkl\"\n",
    "        army_noise_data.append(LoadModRecData(data_file, 1., 0., 0., load_mods=[\"NOISE\"], verbose=False).signalData)\n",
    "\n",
    "    army_noise_data = np.concatenate(army_noise_data)\n",
    "\n",
    "    print(army_noise_data.shape)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make random gaussian noise\n",
    "if train_snr:\n",
    "    gaussian_noise = np.random.standard_normal(army_noise_data.shape)\n",
    "    std = np.random.uniform(-2,2,gaussian_noise.shape[0])[:,np.newaxis]\n",
    "    gaussian_noise = std[:,np.newaxis]*gaussian_noise\n",
    "\n",
    "    noise_data = np.concatenate((army_noise_data, gaussian_noise))\n",
    "    noise_labels = np.zeros((noise_data.shape[0],3))\n",
    "    noise_labels[:,2] = 1\n",
    "\n",
    "    noise_snr = -100*np.ones((noise_data.shape[0],1))\n",
    "    print(\"noise\", noise_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add noise data to training set\n",
    "if train_snr:\n",
    "    data = np.concatenate((data, noise_data))\n",
    "    labels = np.concatenate((labels, noise_labels))\n",
    "    snr = np.concatenate((snr, noise_snr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2555904, 2, 1024)\n",
      "(2555904, 24)\n",
      "(2555904, 1)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(labels.shape)\n",
    "print(snr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, title='Confusion matrix', cmap=plt.cm.Blues, labels=[]):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(labels))\n",
    "    plt.xticks(tick_marks, labels, rotation=45)\n",
    "    plt.yticks(tick_marks, labels)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Real Model\n",
    "\n",
    "# def inception(input_img, height = 1, fs=[64,64,64,64,64], with_residual=False, tw_tower=False):\n",
    "#     tower_1 = Conv2D(filters=fs[0], kernel_size=[height, 1], padding='same', activation='relu')(input_img)\n",
    "#     tower_2 = Conv2D(filters=fs[2], kernel_size=[height, 1], padding='same', activation='relu')(input_img)\n",
    "#     tower_2 = Conv2D(filters=fs[3], kernel_size=[height, 9], padding='same', activation='relu')(tower_2)\n",
    "#     tower_3 = Conv2D(filters=fs[2], kernel_size=[height, 1], padding='same', activation='relu')(input_img)\n",
    "#     tower_3 = Conv2D(filters=fs[3], kernel_size=[height, 4], padding='same', activation='relu')(tower_3)\n",
    "#     if tw_tower:\n",
    "#         tower_5 = Conv2D(filters=fs[2], kernel_size=[height, 1], padding='same', activation='relu')(input_img)\n",
    "#         tower_5 = Conv2D(filters=fs[3], kernel_size=[height, 12], padding='same', activation='relu')(tower_5)\n",
    "#     tower_4 = MaxPooling2D(3, strides=1, padding='same')(input_img)\n",
    "#     tower_4 = Conv2D(filters=fs[4], kernel_size=1, padding='same', activation='relu')(tower_4)\n",
    "#     if tw_tower:\n",
    "#         output = keras.layers.concatenate([tower_1, tower_2, tower_3, tower_4, tower_5], axis = 3)\n",
    "#     else:\n",
    "#         output = keras.layers.concatenate([tower_1, tower_2, tower_3, tower_4], axis = 3)\n",
    "#     if with_residual and output.shape==input_img.shape:\n",
    "#         output = output+input_img\n",
    "#     print()\n",
    "#     return output\n",
    "\n",
    "# def out_tower(x, num_classes, dr=0.5):\n",
    "#     x = Dropout(dr)(x)\n",
    "#     output = Flatten()(x)\n",
    "#     out    = Dense(num_classes, activation='softmax')(output)\n",
    "#     return out\n",
    "\n",
    "# def googleNet(x, data_format='channels_last', num_classes=24,num_layers=[1,2,3,2], features=[1,1,1,1,1]):\n",
    "#     x = Reshape(in_shp + (1,), input_shape=in_shp)(x)\n",
    "#     x = Conv2D(filters=64*features[0], kernel_size=[2,7], strides=[2,2], data_format=data_format, padding='same', activation='relu')(x)\n",
    "#     x = MaxPooling2D([1, 3], strides=[1,2], padding='same')(x)\n",
    "#     for dep in range(num_layers[0]):\n",
    "#         y = x\n",
    "#         x = Conv2D(filters=192*features[1], kernel_size=[1, 3], strides=[1,1], padding='same', activation='relu')(x)\n",
    "#         if dep > 0:\n",
    "#             x = add([x,y])\n",
    "#     x = MaxPooling2D([1,3], strides=[1,2], padding='same')(x)\n",
    "#     for dep in range(num_layers[1]):\n",
    "#         y = x\n",
    "#         x = inception(x, height=2, fs=np.array([64,64,64,64,64])*features[2], tw_tower=True)\n",
    "#         if dep > 0:\n",
    "#             x = add([x,y])\n",
    "#     x = MaxPooling2D([1,3], strides=2, padding='same')(x)\n",
    "#     for dep in range(num_layers[2]):\n",
    "#         y = x\n",
    "#         x = inception(x, height=2, fs=np.array([32,32,32,32,32])*features[3], with_residual=True)\n",
    "#         if dep > 0:\n",
    "#             x = add([x,y])\n",
    "\n",
    "#     x = Conv2D(filters=128, kernel_size=1, padding='same', activation='relu')(x)\n",
    "#     out = out_tower(x, num_classes, dr=0.5)\n",
    "#     #out = Average()([out_mid, out_late])\n",
    "#     return out\n",
    "\n",
    "\n",
    "# in_shp = (2, 1024)\n",
    "# input_img = Input(shape=in_shp)\n",
    "# out = googleNet(input_img,data_format='channels_last', num_classes=labels[0].shape[0])\n",
    "# model = Model(inputs=input_img, outputs=out)\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 2, 1024)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 2, 1024, 1)   0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "complex__conv1d_24 (Complex_Con (None, 2, 512, 64)   896         reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 2, 256, 64)   0           complex__conv1d_24[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "complex__conv1d_25 (Complex_Con (None, 2, 256, 128)  49408       max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 2, 128, 128)  0           complex__conv1d_25[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "complex__conv1d_27 (Complex_Con (None, 2, 128, 32)   8256        max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "complex__conv1d_29 (Complex_Con (None, 2, 128, 32)   8256        max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 2, 128, 128)  0           max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "complex__conv1d_31 (Complex_Con (None, 2, 128, 32)   8256        max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "complex__conv1d_26 (Complex_Con (None, 2, 128, 32)   8256        max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "complex__conv1d_28 (Complex_Con (None, 2, 128, 32)   18496       complex__conv1d_27[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "complex__conv1d_30 (Complex_Con (None, 2, 128, 32)   8256        complex__conv1d_29[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "complex__conv1d_33 (Complex_Con (None, 2, 128, 32)   8256        max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "complex__conv1d_32 (Complex_Con (None, 2, 128, 32)   24640       complex__conv1d_31[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 2, 128, 160)  0           complex__conv1d_26[0][0]         \n",
      "                                                                 complex__conv1d_28[0][0]         \n",
      "                                                                 complex__conv1d_30[0][0]         \n",
      "                                                                 complex__conv1d_33[0][0]         \n",
      "                                                                 complex__conv1d_32[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 2, 64, 160)   0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "complex__conv1d_35 (Complex_Con (None, 2, 64, 32)    10304       max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "complex__conv1d_37 (Complex_Con (None, 2, 64, 32)    10304       max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D) (None, 2, 64, 160)   0           max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "complex__conv1d_34 (Complex_Con (None, 2, 64, 32)    10304       max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "complex__conv1d_36 (Complex_Con (None, 2, 64, 32)    18496       complex__conv1d_35[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "complex__conv1d_38 (Complex_Con (None, 2, 64, 32)    8256        complex__conv1d_37[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "complex__conv1d_39 (Complex_Con (None, 2, 64, 32)    10304       max_pooling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 2, 64, 128)   0           complex__conv1d_34[0][0]         \n",
      "                                                                 complex__conv1d_36[0][0]         \n",
      "                                                                 complex__conv1d_38[0][0]         \n",
      "                                                                 complex__conv1d_39[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "complex__conv1d_41 (Complex_Con (None, 2, 64, 32)    8256        concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "complex__conv1d_43 (Complex_Con (None, 2, 64, 32)    8256        concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling2D) (None, 2, 64, 128)   0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "complex__conv1d_40 (Complex_Con (None, 2, 64, 32)    8256        concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "complex__conv1d_42 (Complex_Con (None, 2, 64, 32)    18496       complex__conv1d_41[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "complex__conv1d_44 (Complex_Con (None, 2, 64, 32)    8256        complex__conv1d_43[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "complex__conv1d_45 (Complex_Con (None, 2, 64, 32)    8256        max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 2, 64, 128)   0           complex__conv1d_40[0][0]         \n",
      "                                                                 complex__conv1d_42[0][0]         \n",
      "                                                                 complex__conv1d_44[0][0]         \n",
      "                                                                 complex__conv1d_45[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 2, 64, 128)   0           concatenate_6[0][0]              \n",
      "                                                                 concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "complex__conv1d_46 (Complex_Con (None, 2, 64, 64)    16512       add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 2, 64, 64)    0           complex__conv1d_46[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 8192)         0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 24)           196632      flatten_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 483,864\n",
      "Trainable params: 483,864\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "### Complex Model\n",
    "def inception(input_img, fs=[64,64,64,64,64], with_residual=False, tw_tower=False):\n",
    "    tower_1 = Complex_Conv1D(filters=fs[0], kernel_size=[1,1], padding='same', activation='relu')(input_img)\n",
    "    tower_2 = Complex_Conv1D(filters=fs[2], kernel_size=[1,1], padding='same', activation='relu')(input_img)\n",
    "    tower_2 = Complex_Conv1D(filters=fs[3], kernel_size=[1,9], padding='same', activation='relu')(tower_2)\n",
    "    tower_3 = Complex_Conv1D(filters=fs[2], kernel_size=[1,1], padding='same', activation='relu')(input_img)\n",
    "    tower_3 = Complex_Conv1D(filters=fs[3], kernel_size=[1,4], padding='same', activation='relu')(tower_3)\n",
    "    if tw_tower:\n",
    "        tower_5 = Complex_Conv1D(filters=fs[2], kernel_size=[1, 1], padding='same', activation='relu')(input_img)\n",
    "        tower_5 = Complex_Conv1D(filters=fs[3], kernel_size=[1, 12], padding='same', activation='relu')(tower_5)\n",
    "    tower_4 = MaxPooling2D(3, strides=1, padding='same')(input_img)\n",
    "    tower_4 = Complex_Conv1D(filters=fs[4], kernel_size=[1, 1], padding='same', activation='relu')(tower_4)\n",
    "    if tw_tower:\n",
    "        output = keras.layers.concatenate([tower_1, tower_2, tower_3, tower_4, tower_5], axis = 3)\n",
    "    else:\n",
    "        output = keras.layers.concatenate([tower_1, tower_2, tower_3, tower_4], axis = 3)\n",
    "    if with_residual and output.shape==input_img.shape:\n",
    "        output = output+input_img\n",
    "    return output\n",
    "\n",
    "def out_tower(x, num_classes, dr=0.5):\n",
    "    x = Dropout(dr)(x)\n",
    "    output = Flatten()(x)\n",
    "    out    = Dense(num_classes, activation='softmax')(output)\n",
    "    return out\n",
    "\n",
    "def googleNet(x, data_format='channels_last', num_classes=24,num_layers=[1,1,2,1], features=[1,1,1,1,1]):\n",
    "    x = Reshape(in_shp + (1,), input_shape=in_shp)(x)\n",
    "    x = Complex_Conv1D(filters=64*features[0], kernel_size=[1,6], strides=[1,2], data_format=data_format, padding='same', activation='relu')(x)\n",
    "    x = MaxPooling2D([1, 3], strides=[1,2], padding='same')(x)\n",
    "    for dep in range(num_layers[0]):\n",
    "        y = x\n",
    "        x = Complex_Conv1D(filters=128*features[1], kernel_size=[1,3], strides=[1,1], padding='same', activation='relu')(x)\n",
    "        if dep > 0:\n",
    "            x = add([x,y])\n",
    "    x = MaxPooling2D([1,3], strides=[1,2], padding='same')(x)\n",
    "    for dep in range(num_layers[1]):\n",
    "        y = x\n",
    "        x = inception(x, fs=np.array([32,32,32,32,32])*features[2], tw_tower=True)\n",
    "        if dep > 0:\n",
    "            x = add([x,y])\n",
    "    x = MaxPooling2D([1,3], strides=[1,2], padding='same')(x)\n",
    "    for dep in range(num_layers[2]):\n",
    "        y = x\n",
    "        x = inception(x, fs=np.array([32,32,32,32,32])*features[3], with_residual=True)\n",
    "        if dep > 0:\n",
    "            x = add([x,y])\n",
    "\n",
    "    x = Complex_Conv1D(filters=64, kernel_size=[1,1], padding='same', activation='relu')(x)\n",
    "    out = out_tower(x, num_classes, dr=0.5)\n",
    "    #out = Average()([out_mid, out_late])\n",
    "    return out\n",
    "\n",
    "\n",
    "in_shp = (2, 1024)\n",
    "input_img = Input(shape=in_shp)\n",
    "out = googleNet(input_img,data_format='channels_last', num_classes=24)\n",
    "model = Model(inputs=input_img, outputs=out)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # Uncomment to visualize architecture\n",
    "# plot_model(model, to_file='model.png', show_shapes = True)\n",
    "\n",
    "# figure(figsize = (15,20))\n",
    "# img = mpimg.imread('model.png')\n",
    "# plt.imshow(img, aspect='auto')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shuffle_data(data,labels, snr=None):\n",
    "    idx = np.random.permutation(labels.shape[0])\n",
    "    if not snr is None:\n",
    "        return data[idx], labels[idx], snr[idx]\n",
    "    return data[idx], labels[idx]\n",
    "\n",
    "def split(data,labels, snr, train, val):\n",
    "    l = data.shape[0]\n",
    "    train_id = l * train // 100\n",
    "    val_id = train_id + l * val // 100\n",
    "         \n",
    "    return  data[:train_id], labels[:train_id], snr[:train_id],                     \\\n",
    "            data[train_id:val_id], labels[train_id:val_id], snr[train_id:val_id],   \\\n",
    "            data[val_id:], labels[val_id:], snr[val_id:] \n",
    "\n",
    "# def normalize(sig):\n",
    "#     print(sig.shape)\n",
    "        \n",
    "def batch_generator(sig_data, sig_labels, batch_size=512, noise=None, shuffle=False, freq_shift=np.pi, normalize=True):\n",
    "    while True:\n",
    "        data = np.copy(sig_data)\n",
    "        labels = np.copy(sig_labels)\n",
    "        N = data.shape[0]\n",
    "\n",
    "        if shuffle:\n",
    "            idx = np.random.permutation(data.shape[0])\n",
    "            data, labels = shuffle_data(data, labels)\n",
    "            \n",
    "        if normalize:\n",
    "            for i in range(data.shape[0]):\n",
    "                sig = data[i][0] + 1j * data[i][1]\n",
    "                sig = sig/np.std(sig)\n",
    "\n",
    "                data[i][0] = sig.real\n",
    "                data[i][1] = sig.imag\n",
    "\n",
    "            \n",
    "        steps = N // batch_size\n",
    "        \n",
    "        for i in range(steps):\n",
    "            beg = i*batch_size\n",
    "            end = beg+batch_size\n",
    "            \n",
    "            batch_data, batch_labels = sig_data[beg:end], sig_labels[beg:end]\n",
    "            \n",
    "            if noise:\n",
    "                x,y,z = batch_data.shape\n",
    "                batch_data += noise * np.random.randn(x, y, z)\n",
    "                \n",
    "            if freq_shift:\n",
    "                shift = np.random.uniform(-freq_shift,freq_shift,batch_data.shape[0])\n",
    "                carrier = np.exp(1j*shift[:,np.newaxis] * np.arange(1024).reshape((1,1024)))\n",
    "                c_r = carrier.real; c_i = carrier.imag\n",
    "                batch_data[:,0,:], batch_data[:,1,:] = batch_data[:,0,:]*c_r - batch_data[:,1,:]*c_i, \\\n",
    "                                                       batch_data[:,0,:]*c_i + batch_data[:,1,:]*c_r\n",
    "\n",
    "\n",
    "            yield batch_data, batch_labels\n",
    "        \n",
    "        if noise:\n",
    "            data = np.copy(sig_data)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data, labels, snr = shuffle_data(data, labels, snr)\n",
    "\n",
    "train_data, train_labels, train_snr, \\\n",
    "val_data, val_labels, val_snr, \\\n",
    "test_data, test_labels, test_snr = split(data, labels, snr, 80, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2555904, 2, 1024)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_batch_size = 512\n",
    "val_batch_size = 512\n",
    "\n",
    "train_generator = batch_generator(train_data, train_labels, batch_size=512, noise=None, shuffle=True, freq_shift=None)\n",
    "val_generator = batch_generator(val_data, val_labels, batch_size=512, noise=None, shuffle=False, freq_shift=None)\n",
    "\n",
    "tsteps = train_data.shape[0] // train_batch_size\n",
    "vsteps = val_data.shape[0] // val_batch_size\n",
    "\n",
    "# print(next(train_generator)[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  (2044723, 2, 1024) (2044723, 24) (2044723, 1)\n",
      "val:  (255590, 2, 1024) (255590, 24) (255590, 1)\n",
      "test:  (255591, 2, 1024) (255591, 24) (255591, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"train: \", train_data.shape, train_labels.shape, train_snr.shape)\n",
    "print(\"val: \", val_data.shape, val_labels.shape, val_snr.shape)\n",
    "print(\"test: \", test_data.shape, test_labels.shape, test_snr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/morads/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:15: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/morads/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., steps_per_epoch=3993, verbose=1, validation_data=<generator..., validation_steps=499, callbacks=[<keras.ca..., epochs=10)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "# model = multi_gpu_model(model, gpus=2)\n",
    "number_of_epochs = 10\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "filepath = '/tmp/morads/convmodrecnets_CNN2_0.5.wts.h5'\n",
    "\n",
    "try:\n",
    "    history = model.fit_generator(train_generator,\n",
    "        nb_epoch=number_of_epochs,\n",
    "        steps_per_epoch=tsteps,\n",
    "        verbose=1,\n",
    "        validation_data=val_generator,\n",
    "        validation_steps=vsteps,\n",
    "         callbacks = [\n",
    "              keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=True, mode='auto'),\n",
    "              keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=0, mode='auto')\n",
    "         ]) \n",
    "except(StopIteration):\n",
    "    pass\n",
    "    \n",
    "model.save('small_complex2.h5')  \n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getSNRindices(snrLabels, snr):\n",
    "    return np.where(snrLabels==snr)[0]\n",
    "\n",
    "def getModIndices(labels, mod):\n",
    "    labl = np.argmax(labels, axis=1)\n",
    "    return np.where(labl==mod)[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filepath = '/tmp/morads/convmodrecnets_CNN2_0.5.wts.h5'\n",
    "model = load_model(filepath)\n",
    "# model = load_model(\"mod_classifier24.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# just accuracies\n",
    "decimate = 5\n",
    "eval_data, eval_snr, eval_labels = np.copy(test_data[::decimate]), np.copy(test_snr[::decimate]), np.copy(test_labels[::decimate])\n",
    "\n",
    "\n",
    "for i in range(eval_data.shape[0]):\n",
    "    eval_data[i] /= np.std(eval_data[i][0] + 1j*eval_data[i][1])\n",
    "        \n",
    "        \n",
    "for SNR in np.unique(snr):\n",
    "    snrIndices = getSNRindices(eval_snr, SNR)\n",
    "    signalData = eval_data[snrIndices]\n",
    "    \n",
    "    \n",
    "    \n",
    "#     shift = np.random.uniform(-np.pi/8,np.pi/8,signalData.shape[0])\n",
    "#     carrier = np.exp(1j*shift[:,np.newaxis] * np.arange(1024).reshape((1,1024)))\n",
    "#     c_r = carrier.real; c_i = carrier.imag\n",
    "    \n",
    "\n",
    "#     temp = signalData.copy()\n",
    "    \n",
    "#     signalData[:,0,:] = temp[:,0,:]*c_r - temp[:,1,:]*c_i\n",
    "#     signalData[:,1,:] = temp[:,0,:]*c_i + temp[:,1,:]*c_r\n",
    "\n",
    "    \n",
    "    signalLabels = np.argmax(eval_labels[snrIndices], axis = 1)\n",
    "    preds = np.argmax(model.predict(signalData), axis = 1)\n",
    "    correct = 0\n",
    "\n",
    "    for i in range(preds.shape[0]):\n",
    "        if preds[i] == signalLabels[i]:\n",
    "            correct+=1\n",
    "    \n",
    "    print(\"SNR: {}, Accuracy: {}, n: {}\".format(SNR, correct/preds.shape[0], signalData.shape[0]))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model = load_model(\"snr_predict3classes_freq_shifted.h5\")\n",
    "\n",
    "decimate = 100\n",
    "\n",
    "eval_data, eval_snr, eval_labels = np.copy(test_data[::decimate]), np.copy(test_snr[::decimate]), np.copy(test_labels[::decimate])\n",
    "\n",
    "for SNR in [10]:\n",
    "    snrIndices = getSNRindices(eval_snr, SNR)\n",
    "    signalData = eval_data[snrIndices]\n",
    "    \n",
    "    shift = np.random.uniform(-np.pi,np.pi,signalData.shape[0])\n",
    "    carrier = np.exp(1j*shift[:,np.newaxis] * np.arange(1024).reshape((1,1024)))\n",
    "    c_r = carrier.real; c_i = carrier.imag\n",
    "    \n",
    "\n",
    "    temp = signalData.copy()\n",
    "    \n",
    "    f = plt.figure(figsize=(8,8))\n",
    "    index = 3\n",
    "    plt.plot(np.abs(fftshift(fft(signalData[index][0].copy() + 1j *signalData[index][1].copy() ))))\n",
    "#     plt.plot(fftshift(fft(signalData[index][0].copy() + 1j *signalData[index][1].copy() )))\n",
    "    plt.show()\n",
    "    \n",
    "    signalData[:,0,:] = temp[:,0,:]*c_r - temp[:,1,:]*c_i\n",
    "    signalData[:,1,:] = temp[:,0,:]*c_i + temp[:,1,:]*c_r\n",
    "    \n",
    "    f = plt.figure(figsize=(8,8))\n",
    "    index = 3\n",
    "    print(shift[index])\n",
    "    plt.plot(np.abs(fftshift(fft(signalData[index][0].copy() + 1j *signalData[index][1].copy() ))))\n",
    "\n",
    "#     plt.plot(fftshift(fft(signalData[index][0].copy() + 1j *signalData[index][1].copy() )).real)\n",
    "#     plt.plot(fftshift(fft(signalData[index][0].copy() + 1j *signalData[index][1].copy() )).imag)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    signalLabels = np.argmax(eval_labels[snrIndices], axis = 1)\n",
    "    preds = np.argmax(model.predict(signalData), axis = 1)\n",
    "    correct = 0\n",
    "\n",
    "    for i in range(preds.shape[0]):\n",
    "        if preds[i] == signalLabels[i]:\n",
    "            correct+=1\n",
    "    \n",
    "    print(\"SNR: {}, Accuracy: {}, n: {}\".format(SNR, correct/preds.shape[0], signalData.shape[0]))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filepath = '/tmp/morads/convmodrecnets_CNN2_0.5.wts.h5'\n",
    "filepath = 'mod_classifier21.h5'\n",
    "model = load_model(filepath)\n",
    "decimate = 5\n",
    "eval_data, eval_snr, eval_labels = np.copy(test_data[::decimate]), np.copy(test_snr[::decimate]), np.copy(test_labels[::decimate])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for SNR in np.arange(-20,31,8):\n",
    "#     snrIndices = getSNRindices(snr, SNR)\n",
    "    \n",
    "#     signalData = data[snrIndices]\n",
    "#     signalLabels = np.argmax(labels[snrIndices], axis = 1)\n",
    "#     preds = np.argmax(model.predict(signalData), axis = 1)\n",
    "    \n",
    "#     correct = 0\n",
    "    \n",
    "#     conf = np.zeros((len(classes),len(classes)))\n",
    "#     confnorm = np.zeros((len(classes),len(classes)))\n",
    "\n",
    "#     for i in range(preds.shape[0]):\n",
    "#         if preds[i] == signalLabels[i]:\n",
    "#             correct+=1\n",
    "#         conf[signalLabels[i], preds[i]] += 1\n",
    "    \n",
    "#     for i in range(0,len(classes)):\n",
    "#         confnorm[i,:] = conf[i,:] / np.sum(conf[i,:])\n",
    "        \n",
    "#     plt.figure(figsize=(10,10))\n",
    "#     plot_confusion_matrix(confnorm, labels=classes, title=\"SNR: {} ConvNet Confusion Matrix\".format(SNR))\n",
    "#     plt.show()\n",
    "\n",
    "        \n",
    "#     print(\"SNR: {}, Accuracy: {}\".format(SNR, correct/preds.shape[0]))\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# print(eval_labels.shape)\n",
    "\n",
    "# print(model.predict(eval_data[:2]).shape)\n",
    "\n",
    "# for i in range(24):\n",
    "#     idx = getModIndices(eval_labels, i)\n",
    "    \n",
    "#     mod_data = eval_data[idx]\n",
    "#     mod_labels = eval_labels[idx]\n",
    "#     mod_snr = eval_snr[idx]\n",
    "    \n",
    "#     snr = 10\n",
    "    \n",
    "#     idx = getSNRindices(mod_snr, snr)\n",
    "#     mod_data = mod_data[idx]\n",
    "#     mod_labels = mod_labels[idx]\n",
    "#     mod_snr = mod_snr[idx]\n",
    "    \n",
    "    \n",
    "#     plt.figure(figsize=(8,8))\n",
    "#     plt.title(classes[i])\n",
    "    \n",
    "#     f = mod_data[0][0] + 1j * mod_data[0][1]\n",
    "#     f = fftshift(fft(f))\n",
    "#     plt.plot(f.real)\n",
    "#     plt.plot(f.imag)\n",
    "    \n",
    "#     plt.show()\n",
    "    \n",
    "    \n",
    "# print(eval_labels.shape)    \n",
    "# # \n",
    "for SNR in np.unique(snr):\n",
    "    snrIndices = getSNRindices(eval_snr, SNR)\n",
    "    signalData = eval_data[snrIndices]\n",
    "    \n",
    "\n",
    "    signalLabels = np.argmax(eval_labels[snrIndices], axis = 1)\n",
    "    preds = np.argmax(model.predict(signalData), axis = 1)\n",
    "    correct = 0\n",
    "\n",
    "    for i in range(preds.shape[0]):\n",
    "        if preds[i] == signalLabels[i]:\n",
    "            correct+=1\n",
    "    \n",
    "    print(\"SNR: {}, Accuracy: {}, n: {}\".format(SNR, correct/preds.shape[0], signalData.shape[0]))\n",
    "      \n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
