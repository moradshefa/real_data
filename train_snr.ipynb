{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/morads/anaconda3/envs/py36/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from data_loader import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "\n",
    "import keras\n",
    "from keras.layers import Input, Reshape, Conv2D, MaxPooling2D, ZeroPadding2D, Flatten, Dropout, Dense, LSTM,Activation\n",
    "from keras.models import Model, load_model\n",
    "from keras.utils import plot_model, multi_gpu_model\n",
    "\n",
    "from scipy import signal\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "def plot_confusion_matrix(cm, title='Confusion matrix', cmap=plt.cm.Blues, labels=[]):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(labels))\n",
    "    plt.xticks(tick_marks, labels, rotation=45)\n",
    "    plt.yticks(tick_marks, labels)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_mod_group = 0\n",
    "val_mod_group = 0\n",
    "test_mod_group = 2\n",
    "\n",
    "num_files = 13\n",
    "# num_files = 5\n",
    "\n",
    "blc = 0\n",
    "\n",
    "CLASSES = ['16PSK', '2FSK_5KHz', '2FSK_75KHz', '8PSK', 'AM_DSB', 'AM_SSB', 'APSK16_c34',\n",
    " 'APSK32_c34', 'BPSK', 'CPFSK_5KHz', 'CPFSK_75KHz', 'FM_NB', 'FM_WB',\n",
    " 'GFSK_5KHz', 'GFSK_75KHz', 'GMSK', 'MSK', 'NOISE', 'OQPSK', 'PI4QPSK', 'QAM16',\n",
    " 'QAM32', 'QAM64', 'QPSK']\n",
    "\n",
    "snr_values = None\n",
    "\n",
    "\n",
    "mods_for_train = 4\n",
    "\n",
    "mods1 = [i for i in range(mods_for_train)]\n",
    "mods1.append(17)\n",
    "mods1 = np.asarray(mods1)\n",
    "\n",
    "mods2 = np.arange(mods_for_train,24)\n",
    "\n",
    "mods3 = np.arange(24)\n",
    "\n",
    "all_mods = [mods1, mods2, mods3]\n",
    "\n",
    "\n",
    "train_modulations = np.asarray([CLASSES[i] for i in all_mods[train_mod_group]])\n",
    "val_modulations = np.asarray([CLASSES[i] for i in all_mods[val_mod_group]])\n",
    "test_modulations = np.asarray([CLASSES[i] for i in all_mods[test_mod_group]])\n",
    "\n",
    "\n",
    "snrDict = {\n",
    "    -10: 0,\n",
    "     -6: 1,\n",
    "     -2: 2,\n",
    "      2: 3,\n",
    "      6: 4,\n",
    "     10: 4\n",
    "}\n",
    "\n",
    "num_classes = len(set(snrDict.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Data Loader] - Loading Datafile,  /datax/yzhang/training_data/training_data_chunk_0.pkl\n",
      "[Data Loader] - Counting Number of Examples in Dataset...\n",
      "[Data Loader] - Number of Examples in Dataset: 60000\n",
      "[Data Loader] - [Modulation Dataset] Adding Collects for: 16PSK\n",
      "[Data Loader] - [Modulation Dataset] Adding Collects for: 2FSK_5KHz\n",
      "[Data Loader] - [Modulation Dataset] Adding Collects for: 2FSK_75KHz\n",
      "[Data Loader] - [Modulation Dataset] Adding Collects for: 8PSK\n",
      "[Data Loader] - [Modulation Dataset] Adding Collects for: NOISE\n",
      "[Data Loader] - Converting to numpy arrays...\n",
      "[Data Loader] - Shuffling Data...\n",
      "[Data Loader] - Splitting Data...\n",
      "[Data Loader] - Train Size: 60000 Validation Size: 0 Test Size: 0\n",
      "[Data Loader] - Done.\n",
      "\n",
      "[Data Loader] - Loading Datafile,  /datax/yzhang/training_data/training_data_chunk_1.pkl\n",
      "[Data Loader] - Counting Number of Examples in Dataset...\n",
      "[Data Loader] - Number of Examples in Dataset: 60000\n",
      "[Data Loader] - [Modulation Dataset] Adding Collects for: 16PSK\n",
      "[Data Loader] - [Modulation Dataset] Adding Collects for: 2FSK_5KHz\n",
      "[Data Loader] - [Modulation Dataset] Adding Collects for: 2FSK_75KHz\n",
      "[Data Loader] - [Modulation Dataset] Adding Collects for: 8PSK\n",
      "[Data Loader] - [Modulation Dataset] Adding Collects for: NOISE\n",
      "[Data Loader] - Converting to numpy arrays...\n",
      "[Data Loader] - Shuffling Data...\n",
      "[Data Loader] - Splitting Data...\n",
      "[Data Loader] - Train Size: 60000 Validation Size: 0 Test Size: 0\n",
      "[Data Loader] - Done.\n",
      "\n",
      "[Data Loader] - Loading Datafile,  /datax/yzhang/training_data/training_data_chunk_2.pkl\n",
      "[Data Loader] - Counting Number of Examples in Dataset...\n",
      "[Data Loader] - Number of Examples in Dataset: 60000\n",
      "[Data Loader] - [Modulation Dataset] Adding Collects for: 16PSK\n",
      "[Data Loader] - [Modulation Dataset] Adding Collects for: 2FSK_5KHz\n",
      "[Data Loader] - [Modulation Dataset] Adding Collects for: 2FSK_75KHz\n",
      "[Data Loader] - [Modulation Dataset] Adding Collects for: 8PSK\n",
      "[Data Loader] - [Modulation Dataset] Adding Collects for: NOISE\n",
      "[Data Loader] - Converting to numpy arrays...\n",
      "[Data Loader] - Shuffling Data...\n",
      "[Data Loader] - Splitting Data...\n",
      "[Data Loader] - Train Size: 60000 Validation Size: 0 Test Size: 0\n",
      "[Data Loader] - Done.\n",
      "\n",
      "[Data Loader] - Loading Datafile,  /datax/yzhang/training_data/training_data_chunk_3.pkl\n",
      "[Data Loader] - Counting Number of Examples in Dataset...\n",
      "[Data Loader] - Number of Examples in Dataset: 60000\n",
      "[Data Loader] - [Modulation Dataset] Adding Collects for: 16PSK\n",
      "[Data Loader] - [Modulation Dataset] Adding Collects for: 2FSK_5KHz\n",
      "[Data Loader] - [Modulation Dataset] Adding Collects for: 2FSK_75KHz\n",
      "[Data Loader] - [Modulation Dataset] Adding Collects for: 8PSK\n",
      "[Data Loader] - [Modulation Dataset] Adding Collects for: NOISE\n",
      "[Data Loader] - Converting to numpy arrays...\n",
      "[Data Loader] - Shuffling Data...\n",
      "[Data Loader] - Splitting Data...\n",
      "[Data Loader] - Train Size: 60000 Validation Size: 0 Test Size: 0\n",
      "[Data Loader] - Done.\n",
      "\n",
      "[Data Loader] - Loading Datafile,  /datax/yzhang/training_data/training_data_chunk_4.pkl\n",
      "[Data Loader] - Counting Number of Examples in Dataset...\n",
      "[Data Loader] - Number of Examples in Dataset: 60000\n",
      "[Data Loader] - [Modulation Dataset] Adding Collects for: 16PSK\n",
      "[Data Loader] - [Modulation Dataset] Adding Collects for: 2FSK_5KHz\n",
      "[Data Loader] - [Modulation Dataset] Adding Collects for: 2FSK_75KHz\n",
      "[Data Loader] - [Modulation Dataset] Adding Collects for: 8PSK\n",
      "[Data Loader] - [Modulation Dataset] Adding Collects for: NOISE\n",
      "[Data Loader] - Converting to numpy arrays...\n",
      "[Data Loader] - Shuffling Data...\n",
      "[Data Loader] - Splitting Data...\n",
      "[Data Loader] - Train Size: 60000 Validation Size: 0 Test Size: 0\n",
      "[Data Loader] - Done.\n",
      "\n",
      "[Data Loader] - Loading Datafile,  /datax/yzhang/training_data/training_data_chunk_5.pkl\n",
      "[Data Loader] - Counting Number of Examples in Dataset...\n",
      "[Data Loader] - Number of Examples in Dataset: 60000\n",
      "[Data Loader] - [Modulation Dataset] Adding Collects for: 16PSK\n",
      "[Data Loader] - [Modulation Dataset] Adding Collects for: 2FSK_5KHz\n",
      "[Data Loader] - [Modulation Dataset] Adding Collects for: 2FSK_75KHz\n",
      "[Data Loader] - [Modulation Dataset] Adding Collects for: 8PSK\n",
      "[Data Loader] - [Modulation Dataset] Adding Collects for: NOISE\n",
      "[Data Loader] - Converting to numpy arrays...\n",
      "[Data Loader] - Shuffling Data...\n",
      "[Data Loader] - Splitting Data...\n",
      "[Data Loader] - Train Size: 60000 Validation Size: 0 Test Size: 0\n",
      "[Data Loader] - Done.\n",
      "\n",
      "[Data Loader] - Loading Datafile,  /datax/yzhang/training_data/training_data_chunk_6.pkl\n",
      "[Data Loader] - Counting Number of Examples in Dataset...\n",
      "[Data Loader] - Number of Examples in Dataset: 60000\n",
      "[Data Loader] - [Modulation Dataset] Adding Collects for: 16PSK\n",
      "[Data Loader] - [Modulation Dataset] Adding Collects for: 2FSK_5KHz\n",
      "[Data Loader] - [Modulation Dataset] Adding Collects for: 2FSK_75KHz\n",
      "[Data Loader] - [Modulation Dataset] Adding Collects for: 8PSK\n",
      "[Data Loader] - [Modulation Dataset] Adding Collects for: NOISE\n",
      "[Data Loader] - Converting to numpy arrays...\n",
      "[Data Loader] - Shuffling Data...\n",
      "[Data Loader] - Splitting Data...\n",
      "[Data Loader] - Train Size: 60000 Validation Size: 0 Test Size: 0\n",
      "[Data Loader] - Done.\n",
      "\n",
      "[Data Loader] - Loading Datafile,  /datax/yzhang/training_data/training_data_chunk_7.pkl\n",
      "[Data Loader] - Counting Number of Examples in Dataset...\n",
      "[Data Loader] - Number of Examples in Dataset: 60000\n",
      "[Data Loader] - [Modulation Dataset] Adding Collects for: 16PSK\n",
      "[Data Loader] - [Modulation Dataset] Adding Collects for: 2FSK_5KHz\n",
      "[Data Loader] - [Modulation Dataset] Adding Collects for: 2FSK_75KHz\n",
      "[Data Loader] - [Modulation Dataset] Adding Collects for: 8PSK\n",
      "[Data Loader] - [Modulation Dataset] Adding Collects for: NOISE\n",
      "[Data Loader] - Converting to numpy arrays...\n",
      "[Data Loader] - Shuffling Data...\n",
      "[Data Loader] - Splitting Data...\n",
      "[Data Loader] - Train Size: 60000 Validation Size: 0 Test Size: 0\n",
      "[Data Loader] - Done.\n",
      "\n",
      "[Data Loader] - Loading Datafile,  /datax/yzhang/training_data/training_data_chunk_8.pkl\n",
      "[Data Loader] - Counting Number of Examples in Dataset...\n",
      "[Data Loader] - Number of Examples in Dataset: 60000\n",
      "[Data Loader] - [Modulation Dataset] Adding Collects for: 16PSK\n",
      "[Data Loader] - [Modulation Dataset] Adding Collects for: 2FSK_5KHz\n",
      "[Data Loader] - [Modulation Dataset] Adding Collects for: 2FSK_75KHz\n",
      "[Data Loader] - [Modulation Dataset] Adding Collects for: 8PSK\n",
      "[Data Loader] - [Modulation Dataset] Adding Collects for: NOISE\n",
      "[Data Loader] - Converting to numpy arrays...\n",
      "[Data Loader] - Shuffling Data...\n",
      "[Data Loader] - Splitting Data...\n",
      "[Data Loader] - Train Size: 60000 Validation Size: 0 Test Size: 0\n",
      "[Data Loader] - Done.\n",
      "\n",
      "[Data Loader] - Loading Datafile,  /datax/yzhang/training_data/training_data_chunk_9.pkl\n",
      "[Data Loader] - Counting Number of Examples in Dataset...\n",
      "[Data Loader] - Number of Examples in Dataset: 60000\n",
      "[Data Loader] - [Modulation Dataset] Adding Collects for: 16PSK\n",
      "[Data Loader] - [Modulation Dataset] Adding Collects for: 2FSK_5KHz\n",
      "[Data Loader] - [Modulation Dataset] Adding Collects for: 2FSK_75KHz\n",
      "[Data Loader] - [Modulation Dataset] Adding Collects for: 8PSK\n",
      "[Data Loader] - [Modulation Dataset] Adding Collects for: NOISE\n",
      "[Data Loader] - Converting to numpy arrays...\n",
      "[Data Loader] - Shuffling Data...\n",
      "[Data Loader] - Splitting Data...\n",
      "[Data Loader] - Train Size: 60000 Validation Size: 0 Test Size: 0\n",
      "[Data Loader] - Done.\n",
      "\n",
      "[Data Loader] - Loading Datafile,  /datax/yzhang/training_data/training_data_chunk_10.pkl\n",
      "[Data Loader] - Counting Number of Examples in Dataset...\n",
      "[Data Loader] - Number of Examples in Dataset: 60000\n",
      "[Data Loader] - [Modulation Dataset] Adding Collects for: 16PSK\n",
      "[Data Loader] - [Modulation Dataset] Adding Collects for: 2FSK_5KHz\n",
      "[Data Loader] - [Modulation Dataset] Adding Collects for: 2FSK_75KHz\n",
      "[Data Loader] - [Modulation Dataset] Adding Collects for: 8PSK\n",
      "[Data Loader] - [Modulation Dataset] Adding Collects for: NOISE\n",
      "[Data Loader] - Converting to numpy arrays...\n",
      "[Data Loader] - Shuffling Data...\n",
      "[Data Loader] - Splitting Data...\n",
      "[Data Loader] - Train Size: 60000 Validation Size: 0 Test Size: 0\n",
      "[Data Loader] - Done.\n",
      "\n",
      "[Data Loader] - Loading Datafile,  /datax/yzhang/training_data/training_data_chunk_11.pkl\n",
      "[Data Loader] - Counting Number of Examples in Dataset...\n",
      "[Data Loader] - Number of Examples in Dataset: 60000\n",
      "[Data Loader] - [Modulation Dataset] Adding Collects for: 16PSK\n",
      "[Data Loader] - [Modulation Dataset] Adding Collects for: 2FSK_5KHz\n",
      "[Data Loader] - [Modulation Dataset] Adding Collects for: 2FSK_75KHz\n",
      "[Data Loader] - [Modulation Dataset] Adding Collects for: 8PSK\n",
      "[Data Loader] - [Modulation Dataset] Adding Collects for: NOISE\n",
      "[Data Loader] - Converting to numpy arrays...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Data Loader] - Shuffling Data...\n",
      "[Data Loader] - Splitting Data...\n",
      "[Data Loader] - Train Size: 60000 Validation Size: 0 Test Size: 0\n",
      "[Data Loader] - Done.\n",
      "\n",
      "[Data Loader] - Loading Datafile,  /datax/yzhang/training_data/training_data_chunk_12.pkl\n",
      "[Data Loader] - Counting Number of Examples in Dataset...\n",
      "[Data Loader] - Number of Examples in Dataset: 60000\n",
      "[Data Loader] - [Modulation Dataset] Adding Collects for: 16PSK\n",
      "[Data Loader] - [Modulation Dataset] Adding Collects for: 2FSK_5KHz\n",
      "[Data Loader] - [Modulation Dataset] Adding Collects for: 2FSK_75KHz\n",
      "[Data Loader] - [Modulation Dataset] Adding Collects for: 8PSK\n",
      "[Data Loader] - [Modulation Dataset] Adding Collects for: NOISE\n",
      "[Data Loader] - Converting to numpy arrays...\n",
      "[Data Loader] - Shuffling Data...\n",
      "[Data Loader] - Splitting Data...\n",
      "[Data Loader] - Train Size: 60000 Validation Size: 0 Test Size: 0\n",
      "[Data Loader] - Done.\n",
      "\n",
      "[Data Loader] - Loading Datafile,  /datax/yzhang/training_data/training_data_chunk_13.pkl\n",
      "[Data Loader] - Counting Number of Examples in Dataset...\n",
      "[Data Loader] - Number of Examples in Dataset: 60000\n",
      "[Data Loader] - [Modulation Dataset] Adding Collects for: 16PSK\n",
      "[Data Loader] - [Modulation Dataset] Adding Collects for: 2FSK_5KHz\n",
      "[Data Loader] - [Modulation Dataset] Adding Collects for: 2FSK_75KHz\n",
      "[Data Loader] - [Modulation Dataset] Adding Collects for: 8PSK\n",
      "[Data Loader] - [Modulation Dataset] Adding Collects for: NOISE\n",
      "[Data Loader] - Converting to numpy arrays...\n",
      "[Data Loader] - Shuffling Data...\n",
      "[Data Loader] - Splitting Data...\n",
      "[Data Loader] - Train Size: 60000 Validation Size: 0 Test Size: 0\n",
      "[Data Loader] - Done.\n",
      "\n",
      "[Data Loader] - Loading Datafile,  /datax/yzhang/training_data/training_data_chunk_14.pkl\n",
      "[Data Loader] - Counting Number of Examples in Dataset...\n",
      "[Data Loader] - Number of Examples in Dataset: 288000\n",
      "[Data Loader] - [Modulation Dataset] Adding Collects for: 16PSK\n",
      "[Data Loader] - [Modulation Dataset] Adding Collects for: 2FSK_5KHz\n",
      "[Data Loader] - [Modulation Dataset] Adding Collects for: 2FSK_75KHz\n",
      "[Data Loader] - [Modulation Dataset] Adding Collects for: 8PSK\n",
      "[Data Loader] - [Modulation Dataset] Adding Collects for: AM_DSB\n",
      "[Data Loader] - [Modulation Dataset] Adding Collects for: AM_SSB\n",
      "[Data Loader] - [Modulation Dataset] Adding Collects for: APSK16_c34\n",
      "[Data Loader] - [Modulation Dataset] Adding Collects for: APSK32_c34\n",
      "[Data Loader] - [Modulation Dataset] Adding Collects for: BPSK\n",
      "[Data Loader] - [Modulation Dataset] Adding Collects for: CPFSK_5KHz\n",
      "[Data Loader] - [Modulation Dataset] Adding Collects for: CPFSK_75KHz\n",
      "[Data Loader] - [Modulation Dataset] Adding Collects for: FM_NB\n",
      "[Data Loader] - [Modulation Dataset] Adding Collects for: FM_WB\n",
      "[Data Loader] - [Modulation Dataset] Adding Collects for: GFSK_5KHz\n",
      "[Data Loader] - [Modulation Dataset] Adding Collects for: GFSK_75KHz\n",
      "[Data Loader] - [Modulation Dataset] Adding Collects for: GMSK\n",
      "[Data Loader] - [Modulation Dataset] Adding Collects for: MSK\n",
      "[Data Loader] - [Modulation Dataset] Adding Collects for: NOISE\n",
      "[Data Loader] - [Modulation Dataset] Adding Collects for: OQPSK\n",
      "[Data Loader] - [Modulation Dataset] Adding Collects for: PI4QPSK\n",
      "[Data Loader] - [Modulation Dataset] Adding Collects for: QAM16\n",
      "[Data Loader] - [Modulation Dataset] Adding Collects for: QAM32\n",
      "[Data Loader] - [Modulation Dataset] Adding Collects for: QAM64\n",
      "[Data Loader] - [Modulation Dataset] Adding Collects for: QPSK\n",
      "[Data Loader] - Converting to numpy arrays...\n",
      "[Data Loader] - Shuffling Data...\n",
      "[Data Loader] - Splitting Data...\n",
      "[Data Loader] - Train Size: 288000 Validation Size: 0 Test Size: 0\n",
      "[Data Loader] - Done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path = \"/datax/yzhang/army_challenge/training_data/\"\n",
    "if blc == 0:\n",
    "    path = \"/datax/yzhang/training_data/\"\n",
    "\n",
    "data = []\n",
    "for i in range(num_files):\n",
    "    data_file = path + \"training_data_chunk_\" + str(i) + \".pkl\"\n",
    "    data.append(LoadModRecData(data_file, 1., 0., 0., load_mods=train_modulations, load_snrs=snr_values, snrDict=snrDict))\n",
    "    \n",
    "\n",
    "    \n",
    "data_file = path + \"training_data_chunk_13.pkl\"\n",
    "valdata = LoadModRecData(data_file, 1., 0., 0., load_mods=val_modulations, load_snrs=snr_values, snrDict=snrDict)\n",
    "    \n",
    "data_file = path + \"training_data_chunk_14.pkl\"\n",
    "testdata = LoadModRecData(data_file, 1., 0., 0., load_mods=test_modulations, load_snrs=snr_values, snrDict=snrDict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 2, 1024)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 2, 1024, 1)   0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 2, 512, 32)   416         reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 2, 256, 32)   0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 2, 256, 32)   3104        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 2, 128, 32)   0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 2, 128, 16)   1040        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 2, 128, 16)   1040        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 2, 128, 32)   0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 2, 128, 16)   1040        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 2, 128, 16)   4112        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 2, 128, 16)   2064        conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 2, 128, 16)   528         max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 2, 128, 64)   0           conv2d_3[0][0]                   \n",
      "                                                                 conv2d_5[0][0]                   \n",
      "                                                                 conv2d_7[0][0]                   \n",
      "                                                                 conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 1, 64, 64)    0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 1, 64, 8)     1032        max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 1, 64, 8)     1032        max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 1, 64, 64)    0           max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 1, 64, 8)     1032        max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 1, 64, 8)     1032        conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 1, 64, 8)     520         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 1, 64, 8)     520         max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 1, 64, 32)    0           conv2d_9[0][0]                   \n",
      "                                                                 conv2d_11[0][0]                  \n",
      "                                                                 conv2d_13[0][0]                  \n",
      "                                                                 conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 1, 32, 32)    0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 1, 32, 8)     264         max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 1, 32, 8)     264         max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 1, 32, 32)    0           max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 1, 32, 8)     264         max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 1, 32, 8)     392         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 1, 32, 8)     264         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 1, 32, 8)     264         max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 1, 32, 32)    0           conv2d_15[0][0]                  \n",
      "                                                                 conv2d_17[0][0]                  \n",
      "                                                                 conv2d_19[0][0]                  \n",
      "                                                                 conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1, 32, 32)    0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 1024)         0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 5)            5125        flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 5)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 25,349\n",
      "Trainable params: 25,349\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def inception(input_img, fs=[64,64,64,64,64],height = 2, widths = [8,4],  with_residual=False):\n",
    "    tower_1 = Conv2D(filters=fs[0], kernel_size=[height, 1], padding='same',activation='relu')(input_img)\n",
    "    tower_2 = Conv2D(filters=fs[2], kernel_size=[height, 1], padding='same',activation='relu')(input_img)\n",
    "    tower_2 = Conv2D(filters=fs[3], kernel_size=[height, widths[0]], padding='same',activation='relu')(tower_2)\n",
    "    tower_3 = Conv2D(filters=fs[2], kernel_size=[height, 1], padding='same',activation='relu')(input_img)\n",
    "    tower_3 = Conv2D(filters=fs[3], kernel_size=[height, widths[1]], padding='same',activation='relu')(tower_3)\n",
    "    tower_4 = MaxPooling2D(3, strides=1, padding='same')(input_img)\n",
    "    tower_4 = Conv2D(filters=fs[4], kernel_size=1, padding='same',activation='relu')(tower_4)\n",
    "    \n",
    "    if len(widths) == 3:\n",
    "        tower_5 = Conv2D(filters=fs[2], kernel_size=[height, 1], padding='same',activation='relu')(input_img)\n",
    "        tower_5 = Conv2D(filters=fs[3], kernel_size=[height, widths[2]], padding='same',activation='relu')(tower_5)\n",
    "        output = keras.layers.concatenate([tower_1, tower_2, tower_3, tower_4, tower_5], axis = 3)\n",
    "    else:\n",
    "        output = keras.layers.concatenate([tower_1, tower_2, tower_3, tower_4], axis = 3)\n",
    "    if with_residual and output.shape==input_img.shape:\n",
    "        output = output+input_img\n",
    "    return output\n",
    "\n",
    "def out_tower(x, dr=0.5):\n",
    "    x = Dropout(dr)(x)\n",
    "    output = Flatten()(x)\n",
    "    logits = Dense(num_classes)(output)\n",
    "    out = Activation('softmax')(logits)\n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "def googleNet(x, data_format='channels_last', num_classes=24, num_layers = [1,1,1,1],features=[1,1,1,1,1]):\n",
    "    x = Reshape(in_shp + (1,), input_shape=in_shp)(x)\n",
    "    x = Conv2D(filters = 32*features[0], kernel_size=[2,6], strides=[1,2], data_format=data_format, padding='same', activation='relu')(x)\n",
    "    x = MaxPooling2D([1, 3], strides=[1,2], padding='same')(x)\n",
    "    for dep in range(num_layers[0]):\n",
    "        x = Conv2D(filters = 32*features[1], kernel_size=[1, 3], strides=[1,1], padding='same', activation='relu')(x)\n",
    "    x = MaxPooling2D([1,3], strides=[1,2], padding='same')(x)\n",
    "    for dep in range(num_layers[1]):\n",
    "        x = inception(x, widths=[8,4], fs=[16,16,16,16,16]*features[2])\n",
    "    x = MaxPooling2D(3, strides=2, padding='same')(x)\n",
    "    for dep in range(num_layers[2]):\n",
    "        x = inception(x, widths=[8,4], fs=[8,8,8,8,8]*features[3], with_residual=True)\n",
    "    x = MaxPooling2D(3, strides=2, padding='same')(x)\n",
    "    for dep in range(num_layers[3]):\n",
    "        x = inception(x, widths=[6,4],height = 1, fs=[8,8,8,8,8]*features[4])\n",
    "        \n",
    "    out = out_tower(x, dr=0.5)\n",
    "    return out\n",
    "\n",
    "in_shp = (2, 1024)\n",
    "input_img = Input(shape=in_shp)\n",
    "\n",
    "# for our final model we used num_layers = [1,2,6,2]\n",
    "out = googleNet(input_img,data_format='channels_last', num_classes=num_classes, num_layers = [1,1,1,1])\n",
    "model = Model(inputs=input_img, outputs=out)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Uncomment to visualize architecture\n",
    "# plot_model(model, to_file='model.png', show_shapes = True)\n",
    "\n",
    "# figure(figsize = (15,20))\n",
    "# img = mpimg.imread('model.png')\n",
    "# plt.imshow(img, aspect='auto')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding generator for file  0\n",
      "Adding generator for file  1\n",
      "Adding generator for file  2\n",
      "Adding generator for file  3\n",
      "Adding generator for file  4\n",
      "Adding generator for file  5\n",
      "Adding generator for file  6\n",
      "Adding generator for file  7\n",
      "Adding generator for file  8\n",
      "Adding generator for file  9\n",
      "Adding generator for file  10\n",
      "Adding generator for file  11\n",
      "Adding generator for file  12\n"
     ]
    }
   ],
   "source": [
    "# We trained till completion\n",
    "train_batch_size, number_of_epochs = 512, 15\n",
    "\n",
    "val_batches = valdata.batch_iter(valdata.train_idx,train_batch_size,number_of_epochs,use_shuffle=False,train_snr=True)\n",
    "vsteps = valdata.train_idx.size//train_batch_size\n",
    "\n",
    "\n",
    "generators = []\n",
    "tsteps = 0\n",
    "for i,d in enumerate(data):\n",
    "    print(\"Adding generator for file \", i)\n",
    "    generators.append(d.batch_iter(d.train_idx,train_batch_size,number_of_epochs,use_shuffle=False,train_snr=True))\n",
    "    tsteps += d.train_idx.size\n",
    "\n",
    "tsteps = tsteps//train_batch_size \n",
    "\n",
    "def train_batches(noise=None):\n",
    "    while True:\n",
    "        batches_x, batches_y = [], []\n",
    "\n",
    "        for gen in generators:\n",
    "            batch_x, batch_y = next(gen)\n",
    "            batches_x.append(batch_x)\n",
    "            batches_y.append(batch_y)\n",
    "            \n",
    "        batches_x = np.concatenate(batches_x)\n",
    "        batches_y = np.concatenate(batches_y)\n",
    "        \n",
    "        if noise:\n",
    "            x,y,z = batches_x.shape\n",
    "            batches_x += noise * np.random.randn(x, y, z)\n",
    "        idx = np.random.permutation(batches_x.shape[0])\n",
    "        \n",
    "        batches_x = batches_x[idx]\n",
    "        batches_y = batches_y[idx]\n",
    "        \n",
    "        for i in range(len(generators)):\n",
    "            beg = i * train_batch_size\n",
    "            end = beg + train_batch_size\n",
    "            yield batches_x[beg:end], batches_y[beg:end]\n",
    "        \n",
    "\n",
    "train_batches = train_batches(noise=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/morads/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:19: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "/home/morads/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:19: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., steps_per_epoch=1523, verbose=1, validation_data=<generator..., validation_steps=117, callbacks=[<keras.ca..., epochs=15)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1523/1523 [==============================] - 119s 78ms/step - loss: 0.0556 - val_loss: 0.0178\n",
      "Epoch 2/15\n",
      "1523/1523 [==============================] - 125s 82ms/step - loss: 4.0195e-04 - val_loss: 0.0077\n",
      "Epoch 3/15\n",
      "1523/1523 [==============================] - 127s 83ms/step - loss: 2.3966e-04 - val_loss: 0.0072\n",
      "Epoch 4/15\n",
      "1523/1523 [==============================] - 135s 89ms/step - loss: 1.0855 - val_loss: 2.6992\n",
      "Epoch 5/15\n",
      "1523/1523 [==============================] - 122s 80ms/step - loss: 2.6846 - val_loss: 2.7021\n",
      "Epoch 6/15\n",
      "1523/1523 [==============================] - 166s 109ms/step - loss: 2.6858 - val_loss: 2.7010\n"
     ]
    }
   ],
   "source": [
    "# model = multi_gpu_model(model, gpus=2)\n",
    "\n",
    "# optimizer = keras.optimizers.Adam(lr=0.005, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "# model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "filepath = '/tmp/morads/convmodrecnets_CNN2_0.5.wts.h5'\n",
    "\n",
    "try:\n",
    "    history = model.fit_generator(train_batches,\n",
    "        nb_epoch=number_of_epochs,\n",
    "        steps_per_epoch=tsteps,\n",
    "        verbose=1,\n",
    "        validation_data=val_batches,\n",
    "        validation_steps=vsteps,\n",
    "         callbacks = [\n",
    "              keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=True, mode='auto'),\n",
    "              keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, verbose=0, mode='auto')\n",
    "         ]) \n",
    "except(StopIteration):\n",
    "    pass\n",
    "\n",
    "model.save('mod_classifier21.h5')  \n",
    "model = load_model(filepath)\n",
    "\n",
    "# print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# filepath = '/tmp/morads/convmodrecnets_CNN2_0.5.wts.h5'\n",
    "\n",
    "model2 = model\n",
    "model = load_model(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model = model2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2437/2437 [==============================] - 350s 144ms/step - loss: 0.7716 - val_loss: 2.7843 <br>\n",
    "2437/2437 [==============================] - 338s 139ms/step - loss: 2.6873 - val_loss: 2.7907 <br>\n",
    "2437/2437 [==============================] - 340s 139ms/step - loss: 2.4595 - val_loss: 0.0896 <br>\n",
    "2437/2437 [==============================] - 339s 139ms/step - loss: 1.8436e-04 - val_loss: 0.0971 <br>\n",
    "2437/2437 [==============================] - 339s 139ms/step - loss: 0.0099 - val_loss: 0.1190 <br>\n",
    "2437/2437 [==============================] - 339s 139ms/step - loss: 1.3700e-04 - val_loss: 0.0890 <br>\n",
    "2437/2437 [==============================] - 339s 139ms/step - loss: 0.0160 - val_loss: 0.1053 <br>\n",
    "2437/2437 [==============================] - 339s 139ms/step - loss: 8.6887e-05 - val_loss: 0.1143 <br>\n",
    "2437/2437 [==============================] - 339s 139ms/step - loss: 3.6859e-04 - val_loss: 0.0962 <br>\n",
    "2437/2437 [==============================] - 339s 139ms/step - loss: 0.0079 - val_loss: 0.1248 <br>\n",
    "2437/2437 [==============================] - 339s 139ms/step - loss: 4.1867e-05 - val_loss: 0.1192 <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes  ['16PSK' '2FSK_5KHz' '2FSK_75KHz' '8PSK' 'AM_DSB' 'AM_SSB' 'APSK16_c34'\n",
      " 'APSK32_c34' 'BPSK' 'CPFSK_5KHz' 'CPFSK_75KHz' 'FM_NB' 'FM_WB'\n",
      " 'GFSK_5KHz' 'GFSK_75KHz' 'GMSK' 'MSK' 'NOISE' 'OQPSK' 'PI4QPSK' 'QAM16'\n",
      " 'QAM32' 'QAM64' 'QPSK']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/morads/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:30: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNR -10 Overall Accuracy:  1.0 Out of 48000\n",
      "SNR -6 Overall Accuracy:  1.0 Out of 48000\n",
      "SNR -2 Overall Accuracy:  0.9999583333333333 Out of 48000\n",
      "SNR 2 Overall Accuracy:  0.9760625 Out of 48000\n",
      "SNR 6 Overall Accuracy:  0.9954375 Out of 48000\n",
      "SNR 10 Overall Accuracy:  0.9984583333333333 Out of 48000\n"
     ]
    }
   ],
   "source": [
    "# Plot confusion matrix\n",
    "\n",
    "# model = load_model(filepath)\n",
    "acc = {}\n",
    "snrs = np.arange(-15,15, 5)\n",
    "\n",
    "classes = testdata.modTypes\n",
    "\n",
    "print(\"classes \", classes)\n",
    "for snr in testdata.snrValues:\n",
    "\n",
    "    # extract classes @ SNR\n",
    "    snrThreshold_lower = snr\n",
    "    snrThreshold_upper = snr+2\n",
    "    snr_bounded_test_indicies = testdata.get_indicies_withSNRthrehsold(testdata.train_idx, snrThreshold_lower, snrThreshold_upper)\n",
    "    \n",
    "    test_X_i = testdata.signalData[snr_bounded_test_indicies]\n",
    "#     test_Y_i = testdata.oneHotLabels[snr_bounded_test_indicies] \n",
    "    test_Y_i = testdata.snrLabels[snr_bounded_test_indicies] \n",
    "\n",
    "    # estimate classes\n",
    "    test_Y_i_hat = model.predict(test_X_i)\n",
    "    conf = np.zeros([num_classes,num_classes])\n",
    "    confnorm = np.zeros([num_classes,num_classes])\n",
    "    for i in range(0,test_X_i.shape[0]):\n",
    "        j = list(test_Y_i[i,:]).index(1)\n",
    "        k = int(np.argmax(test_Y_i_hat[i,:]))\n",
    "        conf[j,k] = conf[j,k] + 1\n",
    "    for i in range(0,num_classes):\n",
    "        confnorm[i,:] = conf[i,:] / np.sum(conf[i,:])\n",
    "#     plt.figure(figsize=(10,10))\n",
    "#     plot_confusion_matrix(confnorm, labels=[\"-10\", \"-6\", \"-2\", \"2\",\"6\", \"10\"], title=\"ConvNet Confusion Matrix (SNR=%d)\"%(snr))\n",
    "    \n",
    "    cor = np.sum(np.diag(conf))\n",
    "    ncor = np.sum(conf) - cor\n",
    "    print(\"SNR\", snr, \"Overall Accuracy: \", cor / (cor+ncor), \"Out of\", len(snr_bounded_test_indicies))\n",
    "    acc[snr] = 1.0*cor/(cor+ncor)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# path = \"/datax/yzhang/training_data/\"\n",
    "# test_mod_group = 1\n",
    "# test_modulations = np.asarray([CLASSES[i] for i in all_mods[1]])\n",
    "\n",
    "# data_file = path + \"training_data_chunk_14.pkl\"\n",
    "# testdata = LoadModRecData(data_file, 1., 0., 0., load_mods=test_modulations, load_snrs=[10], snrDict=snrDict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes  ['16PSK' '2FSK_5KHz' '2FSK_75KHz' '8PSK' 'AM_DSB' 'AM_SSB' 'APSK16_c34'\n",
      " 'APSK32_c34' 'BPSK' 'CPFSK_5KHz' 'CPFSK_75KHz' 'FM_NB' 'FM_WB'\n",
      " 'GFSK_5KHz' 'GFSK_75KHz' 'GMSK' 'MSK' 'NOISE' 'OQPSK' 'PI4QPSK' 'QAM16'\n",
      " 'QAM32' 'QAM64' 'QPSK']\n",
      "Overall Accuracy:  0.9949861111111111 Out of 48000\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAqsAAALICAYAAABYe7kFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8438294160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Plot confusion matrix\n",
    "\n",
    "# model = load_model('mod_classifier21.h5')\n",
    "acc = {}\n",
    "snrs = np.arange(-15,15, 5)\n",
    "\n",
    "classes = testdata.modTypes\n",
    "\n",
    "print(\"classes \", classes)\n",
    "\n",
    "test_X_i = np.copy(testdata.signalData)\n",
    "\n",
    "\n",
    "#### adding noise\n",
    "# x,y,z = test_X_i.shape\n",
    "# noise = 0.5\n",
    "# test_X_i += noise * np.random.randn(x, y, z)\n",
    "#####\n",
    "\n",
    "\n",
    "\n",
    "#     test_Y_i = testdata.oneHotLabels[snr_bounded_test_indicies] \n",
    "test_Y_i = testdata.snrLabels\n",
    "\n",
    "# estimate classes\n",
    "test_Y_i_hat = model.predict(test_X_i)\n",
    "conf = np.zeros([num_classes,num_classes])\n",
    "confnorm = np.zeros([num_classes,num_classes])\n",
    "for i in range(0,test_X_i.shape[0]):\n",
    "    j = list(test_Y_i[i,:]).index(1)\n",
    "    k = int(np.argmax(test_Y_i_hat[i,:]))\n",
    "    conf[j,k] = conf[j,k] + 1\n",
    "for i in range(0,num_classes):\n",
    "    confnorm[i,:] = conf[i,:] / np.sum(conf[i,:])\n",
    "plt.figure(figsize=(10,10))\n",
    "plot_confusion_matrix(confnorm, labels=[\"-10\",\"-6\",\"-2\",\"2\",\"6,10\"], title=\"ConvNet Confusion Matrix\")\n",
    "\n",
    "cor = np.sum(np.diag(conf))\n",
    "ncor = np.sum(conf) - cor\n",
    "print(\"Overall Accuracy: \", cor / (cor+ncor), \"Out of\", len(snr_bounded_test_indicies))\n",
    "acc[snr] = 1.0*cor/(cor+ncor)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
